# Pokemon- TEXT TO IMAGE


### Contents
1. [Introduction](#introduction)
2. [Goal](#goal)
3. [Research](#research)
4. [Data](#data)
5. [Modeling](#modeling)
6. [Results](#results)
7. [Conclusion](#conclusion)
8. [References](#references)

## Introduction
This project explores the realm of text-to-image generation, focusing on Generative Adversarial Networks (GANs) and diffusion models. The goal is to delve into the complexities of translating textual descriptions into visually coherent images using advanced machine learning techniques.

## Goal
The objective is to deepen understanding in text-to-image generation, experimenting with GANs and diffusion models. The project aims to push the boundaries of creativity and automation by generating high-quality images from textual input.

## Research
The research covers recent advances in text-to-image models, emphasizing GANs and diffusion models. Notable examples include DALL-E, VQ-GAN+CLIP, and AttnGAN for GANs, and Imagen, Latent Diffusion Models, and Text-to-Image Diffusion Models for diffusion models.

## Data
The project starts with the Pokemon dataset, applying data augmentation techniques using Albumentations. The dataset is enriched with diverse perspectives and variations through resizing, cropping, and transformations.

## Modeling
The modeling section explores traditional GAN techniques and incorporates pre-trained models from Hugging Face. The GAN model is designed to generate realistic Pokemon images. Regular monitoring of losses ensures the model's stability and convergence.

## Results
1. Successful completion of GANs tutorial on the Pokemon dataset.
2. Development of a Python application using Tkinter and streamlit for image generation with diffusion models.

## Conclusion
The project achieves its objectives by exploring GANs, implementing data augmentation, and developing a Python application. Valuable insights are gained into text-to-image generation, showcasing the potential and limitations of different models.

## References
- [DALL-E: Creating Images from Text](link-to-paper-1)
- [Taming Transformers for High-Resolution Image Synthesis](link-to-paper-2)
- [AttnGAN: Fine-Grained Text to Image Generation with Attentional GANs](link-to-paper-3)
- [Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](link-to-paper-4)
- [Latent Diffusion Models for Text-to-Image Generation](link-to-paper-5)

Feel free to explore the project and contribute!

